data = matched_censusdata)
summary(col8)
hist(matched_censusdata$mean_grad_new)
hist(matched_censusdata$mean_grad_new[matched_censusdata$T == 0])
hist(matched_censusdata$mean_grad_new)
hist(matched_censusdata$mean_grad_new[matched_censusdata$T == 0])
hist(matched_censusdata$mean_grad_new[matched_censusdata$T == 1])
sharp_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new |
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 8)
summary(sharp_rdd)
plot(sharp_rdd)
fuzzy_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 8)
summary(fuzzy_rdd)
plot(fuzzy_rdd)
plot(sharp_rdd)
plot(fuzzy_rdd)
stargazer(sharp_rdd)
fuzzy_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 10)
summary(fuzzy_rdd)
plot(fuzzy_rdd)
fuzzy_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 12)
summary(fuzzy_rdd)
plot(fuzzy_rdd)
fuzzy_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 13)
summary(fuzzy_rdd)
fuzzy_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 13,
cluster = placecode0)
fuzzy_rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 13,
cluster = matched_censusdata$placecode0)
summary(fuzzy_rdd)
fuzzy_rdd$est
fuzzy_rdd$est[1]
fuzzy_rdd$se[1]
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 9,
cluster = matched_censusdata$placecode0)
# Sharp, c = 9
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 9,
cluster = matched_censusdata$placecode0)
rdd$est[1]
rdd$se[1]
# Sharp, c = 9
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 9,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 9
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 9,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 10
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 10,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 9
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 9,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 10
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 10,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 11
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 11,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 12
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 12,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 13
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 13,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Sharp, c = 13
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 13,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Fuzzy, c = 9
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 9,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Fuzzy, c = 10
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 10,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Fuzzy, c = 11
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 11,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Fuzzy, c = 12
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 12,
cluster = matched_censusdata$placecode0)
summary(rdd)
# Fuzzy, c = 13
rdd <- RDestimate(d_prop_emp_f ~ mean_grad_new + T|
kgrid10 + hhdens10 +
base_hhpovrate0 + prop_head_f_a0 +
sexratio0_a + indian10 + kroad10 +
ktown10 + prop_matric_m0 + prop_matric_f0 +
d_prop_waterclose +
d_prop_flush,
data = matched_censusdata,
cutpoint = 13,
cluster = matched_censusdata$placecode0)
summary(rdd)
## set working directory for Mac and PC
rm(list=ls())
setwd("~/UChiGit/Skwad/Empirical Analysis III/Problem Sets")
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
packages <- c("tidyverse", "data.table", "foreign", "stargazer", "rdd", "ggplot2", "lfe", "rdrobust", "ivpack")
lapply(packages, library, character.only = TRUE)
## load up data
data <- read.dta("PS5.dta")
## -----
# 1. Describe the data
stargazer(data, digits=2, out="Pset5_ChaseTomJeanne/table_q1.tex")
View(data)
packages <- c("tidyverse", "data.table", "foreign",
"stargazer", "rdd", "ggplot2", "lfe",
"rdrobust", "ivpack", "codebook")
lapply(packages, library, character.only = TRUE)
install.packages("codebook")
codebook(data)
codebook::codebook(data)
## -----
# 2. Estimate the regression on the sample of fast food restaurants in Feb-Mar 1992
q2 <- felm(data=data[data$post==0,], empft ~ minwage + nregs + hrsopen + d2 + d3 + d4)
## ------
# 3. Interpret gamma, the coefficient in front of min-wage (TODO) & calculate a 90\% confidence interval
# CI = gamma +/- t_{0.9} se/((N)^0.5)
# t_{0.9} = 1.64
CI_gamma = cbind(CIlower = q2$coefficients[2] - 1.64 * q2$se[2] / (q2$N)^0.5,
CIupper = q2$coefficients[2] + 1.64 * q2$se[2] / (q2$N)^0.5)
CI_gamma
View(q2)
## -----
# 4. Use the sum of squares table from the regression output to calculate the R^2 and the standard error of the regression
pre = data[data$post==0,] #restrict to Feb-March data --> actually use q2$response instead, as not all obs were used in the regression because NA
ybar = mean(q2$response) # on
SStot = sum((q2$response - ybar)^2)
SSres = sum(q2$residuals^2)
R2 = 1 - SSres / SStot
R2
SStot = sum(q2$response^2)
SSres/SStot
R2 = 1 - SSres / SStot
R2
# Why is it not this?:
ESS = sum(q2$response^2)
TSS = sum(pre$empft^2)
R2alt = ESS/TSS
R2alt
pre_nona <- subset(pre, !is.na(empft))
TSS = sum(pre$empft^2)
# Why is it not this?:
ESS = sum(q2$response^2)
pre_nona <- subset(pre, !is.na(empft))
TSS = sum(pre_nona$empft^2)
R2alt = ESS/TSS
R2alt
# Why is it not this? I am prolly missing something dumb, but
# I'm not sure why SStot is calculated as deviation from mean
# and not deviation from y
ESS = sum(q2$fitted.values^2)
pre_nona <- subset(pre, !is.na(empft))
TSS = sum(pre_nona$empft^2)
R2alt = ESS/TSS
R2alt
## -----
# 4. Use the sum of squares table from the regression output to calculate the R^2 and the standard error of the regression
pre = data[data$post==0,] #restrict to Feb-March data --> actually use q2$response instead, as not all obs were used in the regression because NA
ybar = mean(q2$response) # on
SStot = sum((q2$response - ybar)^2)
SSres = sum(q2$residuals^2)
R2 = 1 - SSres / SStot
R2
# Why is it not this? I am prolly missing something dumb, but
# I'm not sure why SStot is calculated as deviation from mean
# and not deviation from y
ESS = sum(q2$fitted.values^2)
pre_nona <- subset(pre, !is.na(empft))
TSS = sum(pre_nona$empft^2)
R2alt = ESS/TSS
R2alt
# Why is it not this? I am prolly missing something dumb, but
# I'm not sure why SStot is calculated as deviation from mean
# and not deviation from y
ESS = sum(q2$fitted.values^2)
TSS = sum(q2$response^2)
R2alt = ESS/TSS
R2alt
RMSE = sqrt(mean((q2$fitted.values - q2$response)^2))
RMSE
#linearHypothesis(q2, c("d2=d3", "d3=0"))
linearHypothesis(q2, c("d2=0", "d3=0"))
linearHypothesis(q2, c("d2=0", "d3=0"), white.adjust = "hc1")
# check ?
linearHypothesis(q2, c("d2 = d3"))
# nu2 = nu3 --> nu2 - nu3 = 0
# var(nu2 - nu3) = var(nu2) + var(nu3) - 2 cov(nu2, nu3)
# t = [nu2 - nu3] / [se(nu2 - nu3)]
# Reject if t > c
vcov_nu = vcov(q2)[5:6,5:6]
var_dnu = vcov_nu[1,1] + vcov_nu[2,2] - 2*vcov_nu[1,2]
t = (q2$coefficients[5] - q2$coefficients[6])/(var_dnu^0.5)
t
c = 1.96 # 95% - should adjust for 390 degrees of freedom?
(t <= c) # Doesn't reject the null
# check ?
linearHypothesis(q2, c("d2 = d3"))
t
t*sqrt(390)
t
t*397/396
linearHypothesis(q2, c("d2 = d3", "d2=0"))
## -----
# 11. Using these stat, calculate a DD estimate of the impact of the min wage law on employment
treat_before = data_sum$mean[data_sum$state==1 & data_sum$post==0]
## ----
# 10. Generate a table of means, a table of standard errors and a table of frequencies for -empft- in each state, each time period
nrows = nrow(data)
data_sum <- data %>%
group_by(state, post) %>%
summarize(mean = round(mean(empft, na.rm=T), 3),
se = round(sd(empft, na.rm=T), 3),
count = n(),
freq = round(count / nrows, 3))
## -----
# 11. Using these stat, calculate a DD estimate of the impact of the min wage law on employment
treat_before = data_sum$mean[data_sum$state==1 & data_sum$post==0]
treat_after = data_sum$mean[data_sum$state==1 & data_sum$post==1]
control_before = data_sum$mean[data_sum$state==0 & data_sum$post==0]
control_after = data_sum$mean[data_sum$state==0 & data_sum$post==1]
DiD11 = (treat_after - control_after) - (treat_before - control_before)
DiD11
## -----
# 12. Specify and estimate the corresponding regression
DiD12 <- felm(data = data, empft ~ post + state + post:state)
stargazer(DiD12, type="text")
## -----
# 12. Specify and estimate the corresponding regression
DiD12 <- felm(data = data, empft ~ post + state + post:state)
stargazer(DiD12, type="text")
DiD11 = (treat_after - control_after) - (treat_before - control_before)
DiD11
# No need to cluster se?
# perhaps add clustering a la White?
q15 <- felm(data=data, empft ~ state + post + state:post + nregs + hrsopen + d2 + d3 + d4)
stargazer(q15, type="text")
codebook(data)
packages <- c("tidyverse", "data.table", "foreign",
"stargazer", "rdd", "ggplot2", "lfe",
"rdrobust", "ivpack", "codebook")
lapply(packages, library, character.only = TRUE)
apply(packages, library, character.only = TRUE)
lapply(packages, library, character.only = TRUE)
description(data)
library(codebook)
codebook(data)
## ------
# 3. Interpret gamma, the coefficient in front of min-wage (TODO) & calculate a 90\% confidence interval
# CI = gamma +/- t_{0.9} se/((N)^0.5)
# t_{0.9} = 1.64
CI_gamma = cbind(CIlower = q2$coefficients[2] - 1.64 * q2$se[2] / (q2$N)^0.5,
CIupper = q2$coefficients[2] + 1.64 * q2$se[2] / (q2$N)^0.5)
CI_gamma
# heteroskedasticity robust (doesn't change answer)
linearHypothesis(q2, c("d2=0", "d3=0"), white.adjust = "hc1")
# heteroskedasticity robust (doesn't change answer)
ht_6 <- linearHypothesis(q2, c("d2=0", "d3=0"), white.adjust = "hc1")
stargazer(ht_6)
#linearHypothesis(q2, c("d2=d3", "d3=0"))
linearHypothesis(q2, c("d2=0", "d3=0"))
# check >- Yes, with one restriction, F test is chi-square
linearHypothesis(q2, c("d2 = d3"))
q2_res <- elm(data=data[data$post==0,], empft ~ minwage + nregs + hrsopen + d4)
q2_res <- felm(data=data[data$post==0,], empft ~ minwage + nregs + hrsopen + d4)
anova(q2_res,q2)
q2_unres <- lm(data=data[data$post==0,], empft ~ minwage + nregs + hrsopen + d2 + d3 + d4)
q2_res <- lm(data=data[data$post==0,], empft ~ minwage + nregs + hrsopen + d4)
anova(q2_res,q2_unres)
# heteroskedasticity robust (doesn't change answer)
linearHypothesis(q2, c("d2=0", "d3=0"), white.adjust = "hc1")
# anova does a proper F test -> both return the same pr. >
ht6 <- anova(q2_res,q2_unres)
stargazer(ht6, out="Pset5_ChaseTomJeanne/table_ht6.tex")
q2_res_eq <- lm(data=data[data$post==0,], empft ~ minwage + nregs + hrsopen + I(d2 + d3) + d4)
# anova
ht7 <- anova(q2_res_eq,q2_unres)
ht7
# check >- Yes, with one restriction, F test is chi-square
linearHypothesis(q2, c("d2 = d3"))
# anova
ht7 <- anova(q2_res_eq,q2_unres)
stargazer(ht7, out="Pset5_ChaseTomJeanne/table_ht7.tex")
stargazer(ht_6)
ht6
var.labels(data)
var_label(data)
hist(matched_censusdata$mean_grad_new, title= "Gradient (Full Sample)")
source('~/Library/Mobile Documents/com~apple~CloudDocs/Dinkelman/Replication Code.R', echo=TRUE)
hist(matched_censusdata$mean_grad_new, title= "Gradient (Full Sample)")
hist(matched_censusdata$mean_grad_new[matched_censusdata$T == 0])
hist(matched_censusdata$mean_grad_new[matched_censusdata$T == 1])
## load up data
data <- read.dta("PS5.dta")
# Chase's
setwd("~/UChiGit/Skwad/Empirical Analysis III/Problem Sets")
options(scipen = 6, digits = 4) # I prefer to view outputs in non-scientific notation
## load up data
data <- read.dta("PS5.dta")
View(data)
mean(data$hrsopen[data$d4 == 1])
mean(data$hrsopen[data$d4 == 1 & !is.na(data$hrsopen)])
mean(data$hrsopen[data$d4 == 0 & !is.na(data$hrsopen)])
q2$se[2]
q2$N
# Should it be this?
CI_gamma = cbind(CIlower = q2$coefficients[2] - 1.943 * q2$se[2] / (q2$N)^0.5,
CIupper = q2$coefficients[2] + 1.943 * q2$se[2] / (q2$N)^0.5)
CI_gamma
q2$rse[2]
R2
# My approach is from p. 74 of Econometric
# Theory and Methods - Davidson & MacKinnon
# Uncentered
ESS = sum(q2$fitted.values^2)
TSS = sum(q2$response^2)
R2altu = ESS/TSS
R2altu
# Uncentered
ESS = sum((q2$fitted.values- mean(q2$fitted.values))^2)
TSS = sum((q2$response - mean(q2$response))^2)
R2altc = ESS/TSS
R2altc
RMSE = sqrt(mean((q2$fitted.values - q2$response)^2))
RMSE
t
