{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pandas for dealing with xlsx\n",
    "import pandas as pd\n",
    "# Old numpy\n",
    "import numpy as np\n",
    "# Stats\n",
    "import statistics as st\n",
    "import statsmodels.api as sm\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "path = \"/Users/chaseabram/UChiGit/Skwad/Empirical Analysis III/Problem Sets/Heckman Pset 4/PS4_Data.xlsx\"\n",
    "# read file\n",
    "xls = pd.ExcelFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhdist(x, y, invcov):\n",
    "    '''Computes the Mahalanobis distance\n",
    "    between x and y, given sample covariance\n",
    "    matrix cov'''\n",
    "    dif = x - y\n",
    "    dist = np.dot(dif,np.dot(invcov, dif.T))\n",
    "    return dist.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum D:  6513\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588117\n",
      "         Iterations 5\n",
      "DataSet 0  ATE part D:  x1    10.719973\n",
      "dtype: float64\n",
      "sum D:  380\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544212\n",
      "         Iterations 7\n",
      "DataSet 1  ATE part D:  x1    1.210326\n",
      "dtype: float64\n",
      "sum D:  74645\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092895\n",
      "         Iterations 10\n",
      "DataSet 2  ATE part D:  x1    3.114354\n",
      "dtype: float64\n",
      "sum D:  5836\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381713\n",
      "         Iterations 7\n",
      "DataSet 3  ATE part D:  x1    6.935575\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get number of sheets (4)\n",
    "num_sheets = len(xls.sheet_names)\n",
    "# initialize data frame\n",
    "dfs = [0]*num_sheets\n",
    "\n",
    "# results data frame\n",
    "# column_names = ['sample', \n",
    "#                'betax0', 'betax1', 'betax2','betaz0', 'betaz1', 'betaz1', 'Dhat']\n",
    "# results = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n",
    "# Mahalanobis tolerance\n",
    "mh = 0.1\n",
    "\n",
    "# read each sheet into data frame and perform analysis\n",
    "for i in range(0,num_sheets):\n",
    "    # Add to data frame\n",
    "    sheet_name = 'DataSet' + str(i)\n",
    "    dfs[i] = pd.read_excel(xls, sheet_name)\n",
    "    \n",
    "    # read in data\n",
    "    Y = dfs[i]['Y']\n",
    "    \n",
    "    D = dfs[i]['D']\n",
    "    print(\"sum D: \", sum(D))\n",
    "    \n",
    "    X = np.zeros((3, len(dfs[i])))\n",
    "    X[0] = [1]*len(dfs[i])\n",
    "    X[1] = dfs[i]['X1']\n",
    "    X[2] = dfs[i]['X2']\n",
    "#     print(np.shape(X[1:4]))\n",
    "    \n",
    "    Z = np.zeros((3, len(dfs[i])))\n",
    "    Z[0] = [1]*len(dfs[i])\n",
    "    Z[1] = dfs[i]['Z1']\n",
    "    Z[2] = dfs[i]['Z2']\n",
    "    \n",
    "    # A\n",
    "    # Need to switch to probit (originally had OLS)\n",
    "#     print(np.shape(np.vstack((X[1:2],Z[1:2]))))\n",
    "    X_A = np.vstack((X,Z[1:3])).T\n",
    "    model_A = sm.Probit(D,X_A)\n",
    "    result_A = model_A.fit()\n",
    "    betas_A = result_A.params\n",
    "#     print(betas)\n",
    "    Dhat_A = result_A.predict(X_A)\n",
    "#     print(min(Dhat_A))\n",
    "    \n",
    "    # B\n",
    "    treat_index = np.where(D > 0)\n",
    "    untreat_index = np.where(D < 1)\n",
    "#     print(np.shape(treat_index))\n",
    "    Dhat_t = Dhat_A[treat_index]\n",
    "    Dhat_u = Dhat_A[untreat_index]\n",
    "#     print(Dhat_t)\n",
    "\n",
    "\n",
    "    # Commented to not deal with plots each time while working\n",
    "#     for Ds in [Dhat_t, Dhat_u]:\n",
    "#         Ds = np.float64(Ds)\n",
    "#         print(\"hist for \", i)\n",
    "#         Dstr = 'Treated'\n",
    "#         if Ds is Dhat_u:\n",
    "#             Dstr = 'Untreated'\n",
    "#         # Histogram to see distribution of \"propensity score\"\n",
    "#         # bins = 'auto'\n",
    "#         plt.hist(Ds, bins=10, density = True, color=\"maroon\")\n",
    "#         plt.grid(axis='y', alpha=0.75)\n",
    "#         plt.xlabel(r'$P[D = 1 \\mid X,Z]$')\n",
    "#         plt.ylabel('Density')\n",
    "#         plt.title(r'$P[D = 1 \\mid X,Z]$ '+ Dstr + \" DataSet\" + str(i))\n",
    "#         # include mean and variance of dist\n",
    "#         Ds_mean = np.mean(Ds)\n",
    "#         Ds_var = np.var(Ds)\n",
    "#         plt.text(Ds_mean +1.5*np.sqrt(Ds_var), 1.1, r'mean = ' + str(round(Ds_mean,2)))\n",
    "#         plt.text(Ds_mean +1.75*np.sqrt(Ds_var), 0.8, r'var = ' + str(round(Ds_var,2)))\n",
    "#         plt.savefig(\"3B dist (Chase) \" + Dstr + \" DataSet\" + str(i))\n",
    "#         plt.show()\n",
    "    \n",
    "    # C - gotta think harder about how to do this\n",
    "    X_C = np.vstack((X[1:3],Z[1:3])).T\n",
    "    cov = np.cov(X_C.T)\n",
    "#     print(np.linalg.det(cov))\n",
    "#     print(len(dfs[i]))\n",
    "#     print(np.shape(X_C))\n",
    "#     print(np.shape(cov))\n",
    "#     mhd = np.dot(cov, X_C.T)\n",
    "#     mhdist_mat = np.dot(X_C, np.dot(cov, X_C.T))\n",
    "#     tic = time.perf_counter()\n",
    "#     for j in range(0, len(dfs[i])):\n",
    "#         2 + 3\n",
    "#         if j % 1000 == 0:\n",
    "#             print(j)\n",
    "#         for k in range(0, len(dfs[i])):\n",
    "#             1 + 4\n",
    "#     toc = time.perf_counter()\n",
    "#     print(i, \" took \", toc - tic)\n",
    "    \n",
    "    # D\n",
    "#     print(np.shape(np.vstack((X[1:2],Z[1:2]))))\n",
    "    X_D = Dhat_A.T\n",
    "    model_D = sm.OLS(Y,X_D)\n",
    "    result_D = model_D.fit()\n",
    "    betas_D = result_D.params\n",
    "    print(\"DataSet\", i, \" ATE part D: \", betas_D)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # means\n",
    "#     mu_1 = np.mean(X[1])\n",
    "#     mu_2 = np.mean(X[2])\n",
    "    \n",
    "#     # var-cov\n",
    "#     Sigma = np.cov(X)\n",
    "#     sigma_1 = math.sqrt(Sigma[1,1])\n",
    "#     sigma_2 = math.sqrt(Sigma[2,2])\n",
    "                       \n",
    "#     # rho\n",
    "#     rho = Sigma[2,1]/(Sigma[1,1]*Sigma[2,2])\n",
    "    \n",
    "#     # run ols with X1 and X2\n",
    "#     model = sm.OLS(Y,X.T)\n",
    "#     result = model.fit()\n",
    "#     betas = result.params\n",
    "    \n",
    "#     # est var of residuals\n",
    "#     sigma_e = np.cov(result.resid)\n",
    "    \n",
    "#     # t stat\n",
    "#     tstat = result.tvalues[2]\n",
    "    \n",
    "#     # t default is reject beta_2 = 0\n",
    "#     t_test = 1\n",
    "    \n",
    "#     # t test for beta 2\n",
    "#     if abs(tstat) < 1.964:\n",
    "#         # t test cannot reject null of beta_2 = 0\n",
    "#         t_test = 0\n",
    "        \n",
    "#         # OVB regression replaces beta_0 and beta_1\n",
    "#         model = sm.OLS(Y,X[0:2].T)\n",
    "#         result = model.fit()\n",
    "#         betas[0:2] = result.params \n",
    "    \n",
    "#     # create new data frame entry with variables\n",
    "#     new_df = pd.DataFrame(np.array([i, mu_1, mu_2, sigma_1, sigma_2, sigma_e,\n",
    "#                           rho, betas[0], betas[1], betas[2], tstat, t_test])).T\n",
    "#     new_df.columns = column_names\n",
    "    \n",
    "#     # add to results data frame\n",
    "#     results = pd.concat([results, new_df])\n",
    "\n",
    "# # save estimates\n",
    "# results.to_csv (\"/Users/chaseabram/UChiGit/Skwad/Empirical Analysis III/Problem Sets/Heckman Pset 4/Q3_output.csv\", index = False, header=True)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3],[4,5,6]]\n",
    "print(a[0][1:])\n",
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
