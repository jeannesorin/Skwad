{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pandas for dealing with xlsx\n",
    "import pandas as pd\n",
    "# Old numpy\n",
    "import numpy as np\n",
    "# Stats\n",
    "import statistics as st\n",
    "import statsmodels.api as sm\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy as sp\n",
    "import scipy.optimize as so\n",
    "import time\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "path = \"/Users/chaseabram/UChiGit/Skwad/Empirical Analysis III/Problem Sets/Heckman Pset 4/PS4_Data.xlsx\"\n",
    "# read file\n",
    "xls = pd.ExcelFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhdist(x, y, invcov):\n",
    "    '''Computes the Mahalanobis distance\n",
    "    between x and y, given sample covariance\n",
    "    matrix cov'''\n",
    "    dif = x - y\n",
    "    dist = np.dot(dif,np.dot(invcov, dif.T))\n",
    "    return dist.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum D:  6513\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588117\n",
      "         Iterations 5\n",
      "DataSet 0  ATE part D:  x1    10.719973\n",
      "dtype: float64\n",
      "sum D:  380\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544212\n",
      "         Iterations 7\n",
      "DataSet 1  ATE part D:  x1    1.210326\n",
      "dtype: float64\n",
      "sum D:  74645\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.092895\n",
      "         Iterations 10\n",
      "DataSet 2  ATE part D:  x1    3.114354\n",
      "dtype: float64\n",
      "sum D:  5836\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381713\n",
      "         Iterations 7\n",
      "DataSet 3  ATE part D:  x1    6.935575\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get number of sheets (4)\n",
    "num_sheets = len(xls.sheet_names)\n",
    "# initialize data frame\n",
    "dfs = [0]*num_sheets\n",
    "\n",
    "# results data frame\n",
    "# column_names = ['sample', \n",
    "#                'betax0', 'betax1', 'betax2','betaz0', 'betaz1', 'betaz1', 'Dhat']\n",
    "# results = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n",
    "# Mahalanobis tolerance\n",
    "mh = 0.1\n",
    "\n",
    "# read each sheet into data frame and perform analysis\n",
    "for i in range(0,num_sheets):\n",
    "    # Add to data frame\n",
    "    sheet_name = 'DataSet' + str(i)\n",
    "    dfs[i] = pd.read_excel(xls, sheet_name)\n",
    "    \n",
    "    # read in data\n",
    "    Y = dfs[i]['Y']\n",
    "    \n",
    "    D = dfs[i]['D']\n",
    "    print(\"sum D: \", sum(D))\n",
    "    \n",
    "    X = np.zeros((3, len(dfs[i])))\n",
    "    X[0] = [1]*len(dfs[i])\n",
    "    X[1] = dfs[i]['X1']\n",
    "    X[2] = dfs[i]['X2']\n",
    "#     print(np.shape(X[1:4]))\n",
    "    \n",
    "    Z = np.zeros((3, len(dfs[i])))\n",
    "    Z[0] = [1]*len(dfs[i])\n",
    "    Z[1] = dfs[i]['Z1']\n",
    "    Z[2] = dfs[i]['Z2']\n",
    "    \n",
    "    # A\n",
    "    # Need to switch to probit (originally had OLS)\n",
    "#     print(np.shape(np.vstack((X[1:2],Z[1:2]))))\n",
    "    X_A = np.vstack((X,Z[1:3])).T\n",
    "    model_A = sm.Probit(D,X_A)\n",
    "    result_A = model_A.fit()\n",
    "    betas_A = result_A.params\n",
    "#     print(betas)\n",
    "    Dhat_A = result_A.predict(X_A)\n",
    "#     print(min(Dhat_A))\n",
    "    \n",
    "    # B\n",
    "    treat_index = np.where(D > 0)\n",
    "    untreat_index = np.where(D < 1)\n",
    "#     print(np.shape(treat_index))\n",
    "    Dhat_t = Dhat_A[treat_index]\n",
    "    Dhat_u = Dhat_A[untreat_index]\n",
    "#     print(Dhat_t)\n",
    "\n",
    "\n",
    "    # Commented to not deal with plots each time while working\n",
    "#     for Ds in [Dhat_t, Dhat_u]:\n",
    "#         Ds = np.float64(Ds)\n",
    "#         print(\"hist for \", i)\n",
    "#         Dstr = 'Treated'\n",
    "#         if Ds is Dhat_u:\n",
    "#             Dstr = 'Untreated'\n",
    "#         # Histogram to see distribution of \"propensity score\"\n",
    "#         # bins = 'auto'\n",
    "#         plt.hist(Ds, bins=10, density = True, color=\"maroon\")\n",
    "#         plt.grid(axis='y', alpha=0.75)\n",
    "#         plt.xlabel(r'$P[D = 1 \\mid X,Z]$')\n",
    "#         plt.ylabel('Density')\n",
    "#         plt.title(r'$P[D = 1 \\mid X,Z]$ '+ Dstr + \" DataSet\" + str(i))\n",
    "#         # include mean and variance of dist\n",
    "#         Ds_mean = np.mean(Ds)\n",
    "#         Ds_var = np.var(Ds)\n",
    "#         plt.text(Ds_mean +1.5*np.sqrt(Ds_var), 1.1, r'mean = ' + str(round(Ds_mean,2)))\n",
    "#         plt.text(Ds_mean +1.75*np.sqrt(Ds_var), 0.8, r'var = ' + str(round(Ds_var,2)))\n",
    "#         plt.savefig(\"3B dist (Chase) \" + Dstr + \" DataSet\" + str(i))\n",
    "#         plt.show()\n",
    "    \n",
    "    # C - gotta think harder about how to do this\n",
    "    X_C = np.vstack((X[1:3],Z[1:3])).T\n",
    "    cov = np.cov(X_C.T)\n",
    "#     print(np.linalg.det(cov))\n",
    "#     print(len(dfs[i]))\n",
    "#     print(np.shape(X_C))\n",
    "#     print(np.shape(cov))\n",
    "#     mhd = np.dot(cov, X_C.T)\n",
    "#     mhdist_mat = np.dot(X_C, np.dot(cov, X_C.T))\n",
    "#     tic = time.perf_counter()\n",
    "#     for j in range(0, len(dfs[i])):\n",
    "#         2 + 3\n",
    "#         if j % 1000 == 0:\n",
    "#             print(j)\n",
    "#         for k in range(0, len(dfs[i])):\n",
    "#             1 + 4\n",
    "#     toc = time.perf_counter()\n",
    "#     print(i, \" took \", toc - tic)\n",
    "    \n",
    "    # D\n",
    "#     print(np.shape(np.vstack((X[1:2],Z[1:2]))))\n",
    "    X_D = Dhat_A.T\n",
    "    model_D = sm.OLS(Y,X_D)\n",
    "    result_D = model_D.fit()\n",
    "    betas_D = result_D.params\n",
    "    print(\"DataSet\", i, \" ATE part D: \", betas_D)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # means\n",
    "#     mu_1 = np.mean(X[1])\n",
    "#     mu_2 = np.mean(X[2])\n",
    "    \n",
    "#     # var-cov\n",
    "#     Sigma = np.cov(X)\n",
    "#     sigma_1 = math.sqrt(Sigma[1,1])\n",
    "#     sigma_2 = math.sqrt(Sigma[2,2])\n",
    "                       \n",
    "#     # rho\n",
    "#     rho = Sigma[2,1]/(Sigma[1,1]*Sigma[2,2])\n",
    "    \n",
    "#     # run ols with X1 and X2\n",
    "#     model = sm.OLS(Y,X.T)\n",
    "#     result = model.fit()\n",
    "#     betas = result.params\n",
    "    \n",
    "#     # est var of residuals\n",
    "#     sigma_e = np.cov(result.resid)\n",
    "    \n",
    "#     # t stat\n",
    "#     tstat = result.tvalues[2]\n",
    "    \n",
    "#     # t default is reject beta_2 = 0\n",
    "#     t_test = 1\n",
    "    \n",
    "#     # t test for beta 2\n",
    "#     if abs(tstat) < 1.964:\n",
    "#         # t test cannot reject null of beta_2 = 0\n",
    "#         t_test = 0\n",
    "        \n",
    "#         # OVB regression replaces beta_0 and beta_1\n",
    "#         model = sm.OLS(Y,X[0:2].T)\n",
    "#         result = model.fit()\n",
    "#         betas[0:2] = result.params \n",
    "    \n",
    "#     # create new data frame entry with variables\n",
    "#     new_df = pd.DataFrame(np.array([i, mu_1, mu_2, sigma_1, sigma_2, sigma_e,\n",
    "#                           rho, betas[0], betas[1], betas[2], tstat, t_test])).T\n",
    "#     new_df.columns = column_names\n",
    "    \n",
    "#     # add to results data frame\n",
    "#     results = pd.concat([results, new_df])\n",
    "\n",
    "# # save estimates\n",
    "# results.to_csv (\"/Users/chaseabram/UChiGit/Skwad/Empirical Analysis III/Problem Sets/Heckman Pset 4/Q3_output.csv\", index = False, header=True)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3],[4,5,6]]\n",
    "print(a[0][1:])\n",
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 99.6666666666672\n",
       " hess_inv: array([[0.66670341, 0.33337432],\n",
       "       [0.33337432, 0.66674133]])\n",
       "      jac: array([-9.53674316e-07, -9.53674316e-07])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 48\n",
       "      nit: 7\n",
       "     njev: 12\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.66666594, 0.3333326 ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sq(x,y):\n",
    "    return x[0]*(x[0]-1) - x[0]*x[1] + x[1]**2 + y\n",
    "\n",
    "so.minimize(sq, [3000, 1000], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaseabram/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/chaseabram/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "called\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[  -24.16106097,     3.55977845,   -39.41490033,  -128.93629659,\n",
       "          420.20449405, -1242.14061388],\n",
       "       [  -23.99865068,     3.76361239,   -39.30464914,  -128.98364829,\n",
       "          419.93206767, -1242.29445247],\n",
       "       [  -24.08899463,     3.91919052,   -39.07268496,  -128.94369163,\n",
       "          420.05902553, -1241.78779943],\n",
       "       [  -24.43681068,     3.60846106,   -39.15600649,  -128.91657835,\n",
       "          420.15584544, -1242.34060926],\n",
       "       [  -24.02919196,     3.47027503,   -39.21564752,  -128.97607788,\n",
       "          420.06434589, -1242.56778878],\n",
       "       [  -24.3722642 ,     3.80867605,   -39.1482932 ,  -129.08274148,\n",
       "          419.28415453, -1243.85526459],\n",
       "       [  -24.38563898,     3.78964144,   -39.37384604,  -128.89074397,\n",
       "          419.98640627, -1242.37078123]]), array([0.00101623, 0.00101624, 0.00101624, 0.00101624, 0.00101625,\n",
       "       0.00101625, 0.00101625]))\n",
       "           fun: 0.0010162318867723392\n",
       "       message: 'Maximum number of function evaluations has been exceeded.'\n",
       "          nfev: 1201\n",
       "           nit: 728\n",
       "        status: 1\n",
       "       success: False\n",
       "             x: array([  -24.16106097,     3.55977845,   -39.41490033,  -128.93629659,\n",
       "         420.20449405, -1242.14061388])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params - beta_11, beta_12, beta_01, beta_02, gamma_1, gamma_2, sig_1, sig_0C, sig_0, sig_-1C\n",
    "def royll(params,Y,D,X,Z):\n",
    "    llsum = 0\n",
    "    print(\"called\")\n",
    "    for i in range(0,10):\n",
    "#         if i % 1000 == 0:\n",
    "#             print(\"i = \", i)\n",
    "#             print(\"Y: \", Y[i])\n",
    "#             print(\"D: \", D[i])\n",
    "#             print(\"X1: \", X[1][i])\n",
    "#             print(\"Z1: \", Z[1][i])\n",
    "#             print(\"X2: \", X[2][i])\n",
    "#             print(\"Z2: \", Z[2][i])\n",
    "#             print(\"i: \", i)\n",
    "#             print(D[i]*np.log(norm.pdf((Y[i] - X[0][i]*params[0] - X[1][i]*params[1])/params[6])))\n",
    "#             llsum += 1\n",
    "            \n",
    "#             print(\"first in: \", norm.pdf((Y[i] - X[1][i]*params[0] - X[2][i]*params[1])/50)* \\\n",
    "#                             norm.cdf((Y[i] - X[1][i]*params[2] - X[2][i]*params[3] \\\n",
    "#                                       - Z[1][i]*params[4] - Z[2][i]*params[5])/50))\n",
    "#             print(\"first in in: \", norm.pdf((Y[i] - X[1][i]*params[0] - X[2][i]*params[1])/50))\n",
    "            \n",
    "#             print(\"second in: \", )\n",
    "#             print(\"D = 1: \", )\n",
    "#             print(\"D = 0: \", )\n",
    "            \n",
    "        llsum += D[i]*np.log(norm.pdf((Y[i] - X[1][i]*params[0] - X[2][i]*params[1])/1000)* \\\n",
    "                            norm.cdf((Y[i] - X[1][i]*params[2] - X[2][i]*params[3] \\\n",
    "                                      - Z[1][i]*params[4] - Z[2][i]*params[5])/1000)) \\\n",
    "            + (1 - D[i])*np.log(norm.pdf((Y[i] - X[1][i]*params[2] - X[2][i]*params[3])/1000)* \\\n",
    "                            (1 - norm.cdf((-Y[i] + X[1][i]*params[0] + X[2][i]*params[1] \\\n",
    "                                      - Z[1][i]*params[4] - Z[2][i]*params[5])/1000)))\n",
    "        \n",
    "    return -1/len(Y)*llsum\n",
    "\n",
    "# royll([8,1,2,3,4,5,6,7,8,9],[1,1],[2,2],[[3,3],[4,4]],[[5,5],[6,6]])\n",
    "# x = [[1,2],[3,4]]\n",
    "# print(np.shape(x))\n",
    "# print(x[1][1])\n",
    "# so.minimize(royll, [5,14],args = ([9],5,5,5))\n",
    "so.minimize(royll, [10,10,10,1,-90,-10],args = (Y,D,X,Z), method = 'Nelder-Mead',\n",
    "           options={'disp': True, 'adaptive': True})\n",
    "\n",
    "# Need to use OLS for initial guess?\n",
    "# Use bootstrap for standard errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5635594628914329"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.cdf(.16)\n",
    "[ -22.10716216,    4.19600077,  -59.18186434, -202.10428755,\n",
    "        383.85892814, -751.14564748,   39.46968815, -104.30197344,\n",
    "         85.88775666,   88.46673923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
